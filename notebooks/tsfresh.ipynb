{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook illustrates the approach of transforming temporal data into tabular data by feature extraction.\n",
    "\n",
    "Using the library TSFresh https://tsfresh.readthedocs.io/en/latest/index.html we can extract temportal features from overlapping rolling windows.\n",
    "\n",
    "The library tsfresh is not performing anomaly detection, it only handles feature engineering. \n",
    "It can be used in combination with any other libary performing anomaly detection. This notebook uses the baseline approach of using sklearn algorithms (see sklearn.ipynb) and illustrates the increased performance of leveraging temporal features instead of independent samples (tabular data) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import evaluation_utils, data_utils\n",
    "\n",
    "import json\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, y = data_utils.get_data('../data/6_cardio.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a dataframe\n",
    "df = pd.DataFrame(data=X)\n",
    "# Tsfresh is expecting a long format to handle multivariate time series\n",
    "long_df = df.reset_index().melt(id_vars='index', var_name='id', value_name='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 40/40 [00:10<00:00,  3.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# set sliding rolling window\n",
    "rolled_df = roll_time_series(long_df, column_id='id', column_sort='index', max_timeshift=30, min_timeshift=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [07:40<00:00, 11.50s/it]  \n"
     ]
    }
   ],
   "source": [
    "# extract temporal features from each rolling window\n",
    "features = extract_features(rolled_df, column_id='id', column_sort='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.reset_index()\n",
    "# drop columns with missing values\n",
    "features = features.dropna(axis=1)\n",
    "# the first two columns are the id and the index\n",
    "cols = features.columns[2:].values\n",
    "# pivot the table to have the features as columns\n",
    "extracted_features = features.pivot(index='level_1', columns='level_0', values=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the rolling window creation is missing the last samples of each time series\n",
    "y = y[extracted_features.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Isolation Forest Results:\n",
      "{\n",
      "    \"AUCROC\": 0.9101201989499861,\n",
      "    \"AUCPR\": 0.6991923507574249,\n",
      "    \"F1\": 0.8268106438927704,\n",
      "    \"Precision\": 0.8131868131868132,\n",
      "    \"Recall\": 0.8409090909090909,\n",
      "    \"Adjusted AUCROC\": 0.9896656534954407,\n",
      "    \"Adjusted AUCPR\": 0.8380952380952381,\n",
      "    \"Adjusted F1\": 0.9119121372655744,\n",
      "    \"Adjusted Precision\": 0.8380952380952381,\n",
      "    \"Adjusted Recall\": 1.0\n",
      "}\n",
      "Results saved to results/tsfresh sklearn Isolation Forest.npz\n",
      "\n",
      "One-Class SVM Results:\n",
      "{\n",
      "    \"AUCROC\": 0.5343465045592706,\n",
      "    \"AUCPR\": 0.10304449648711944,\n",
      "    \"F1\": 0.1868348242363068,\n",
      "    \"Precision\": 0.10304449648711944,\n",
      "    \"Recall\": 1.0,\n",
      "    \"Adjusted AUCROC\": 0.5343465045592706,\n",
      "    \"Adjusted AUCPR\": 0.10304449648711944,\n",
      "    \"Adjusted F1\": 0.1868348242363068,\n",
      "    \"Adjusted Precision\": 0.10304449648711944,\n",
      "    \"Adjusted Recall\": 1.0\n",
      "}\n",
      "Results saved to results/tsfresh sklearn One-Class SVM.npz\n",
      "\n",
      "Local Outlier Factor Results:\n",
      "{\n",
      "    \"AUCROC\": 0.5390266648245372,\n",
      "    \"AUCPR\": 0.1082726307190887,\n",
      "    \"F1\": 0.1762627893112702,\n",
      "    \"Precision\": 0.09665019220208676,\n",
      "    \"Recall\": 1.0,\n",
      "    \"Adjusted AUCROC\": 0.9537993920972645,\n",
      "    \"Adjusted AUCPR\": 0.5365853658536586,\n",
      "    \"Adjusted F1\": 0.6984081532167806,\n",
      "    \"Adjusted Precision\": 0.5365853658536586,\n",
      "    \"Adjusted Recall\": 1.0\n",
      "}\n",
      "Results saved to results/tsfresh sklearn Local Outlier Factor.npz\n"
     ]
    }
   ],
   "source": [
    "# Define the anomaly detection methods\n",
    "methods = {\n",
    "    \"Isolation Forest\": IsolationForest(contamination=0.1),\n",
    "    \"One-Class SVM\": OneClassSVM(nu=0.1),\n",
    "    \"Local Outlier Factor\": LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "}\n",
    "\n",
    "# Apply each method\n",
    "for name, method in methods.items():\n",
    "    if name == \"Local Outlier Factor\":\n",
    "        predicted_anomalies = method.fit_predict(extracted_features)\n",
    "    else:\n",
    "        method.fit(extracted_features)\n",
    "        predicted_anomalies = method.predict(extracted_features)\n",
    "    \n",
    "    # Reshape the prediction values to 0 for valid, 1 for anomalies \n",
    "    predicted_anomalies[predicted_anomalies == 1] = 0\n",
    "    predicted_anomalies[predicted_anomalies == -1] = 1\n",
    "\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    scores = evaluation_utils.run_evaluation(y, predicted_anomalies, do_point_adjustment=True)\n",
    "    print(json.dumps(scores, indent=4))\n",
    "    # Save the results to a file\n",
    "    data_utils.save_results(f\"results/tsfresh sklearn {name}.npz\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook illustrates the approach of transforming temporal data into tabular data by feature extraction.\n",
    "Using the library TSFresh https://tsfresh.readthedocs.io/en/latest/index.html we can extract temportal features from overlapping rolling windows.\n",
    "\n",
    "This notebook shows the increased performance of performing AD on temporal features compared to tabular data (see sklearn.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import evaluation_utils, data_utils\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, y = data_utils.get_data('../data/6_cardio.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a dataframe\n",
    "df = pd.DataFrame(data=X)\n",
    "# Tsfresh is expecting a long format to handle multivariate time series\n",
    "long_df = df.reset_index().melt(id_vars='index', var_name='id', value_name='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 40/40 [00:11<00:00,  3.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# set sliding rolling window\n",
    "rolled_df = roll_time_series(long_df, column_id='id', column_sort='index', max_timeshift=30, min_timeshift=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [05:55<00:00,  8.89s/it]\n"
     ]
    }
   ],
   "source": [
    "# extract temporal features from each rolling window\n",
    "features = extract_features(rolled_df, column_id='id', column_sort='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.reset_index()\n",
    "# drop columns with missing values\n",
    "features = features.dropna(axis=1)\n",
    "# the first two columns are the id and the index\n",
    "cols = features.columns[2:].values\n",
    "# pivot the table to have the features as columns\n",
    "extracted_features = features.pivot(index='level_1', columns='level_0', values=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the rolling window creation is missing the last samples of each time series\n",
    "y = y[extracted_features.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest Results:\n",
      "{'AUCROC': 0.8786715943630837, 'AUCPR': 0.615398124665011, 'F1': 0.7709447221072506, 'Precision': 0.7582417582417582, 'Recall': 0.7840909090909091, 'Adjusted AUCROC': 0.9866261398176293, 'Adjusted AUCPR': 0.8, 'Adjusted F1': 0.8888839506447186, 'Adjusted Precision': 0.8, 'Adjusted Recall': 1.0}\n",
      "One-Class SVM Results:\n",
      "{'AUCROC': 0.5343465045592706, 'AUCPR': 0.10304449648711944, 'F1': 0.1868348242363068, 'Precision': 0.10304449648711944, 'Recall': 1.0, 'Adjusted AUCROC': 0.5343465045592706, 'Adjusted AUCPR': 0.10304449648711944, 'Adjusted F1': 0.1868348242363068, 'Adjusted Precision': 0.10304449648711944, 'Adjusted Recall': 1.0}\n",
      "Local Outlier Factor Results:\n",
      "{'AUCROC': 0.5390266648245372, 'AUCPR': 0.1082726307190887, 'F1': 0.1762627893112702, 'Precision': 0.09665019220208676, 'Recall': 1.0, 'Adjusted AUCROC': 0.9537993920972645, 'Adjusted AUCPR': 0.5365853658536586, 'Adjusted F1': 0.6984081532167806, 'Adjusted Precision': 0.5365853658536586, 'Adjusted Recall': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Define the anomaly detection methods\n",
    "methods = {\n",
    "    \"Isolation Forest\": IsolationForest(contamination=0.1),\n",
    "    \"One-Class SVM\": OneClassSVM(nu=0.1),\n",
    "    \"Local Outlier Factor\": LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "}\n",
    "\n",
    "# Apply each method\n",
    "for name, method in methods.items():\n",
    "    if name == \"Local Outlier Factor\":\n",
    "        y_pred = method.fit_predict(extracted_features)\n",
    "    else:\n",
    "        method.fit(extracted_features)\n",
    "        y_pred = method.predict(extracted_features)\n",
    "    \n",
    "    # Reshape the prediction values to 0 for valid, 1 for fraud. \n",
    "    y_pred[y_pred == 1] = 0\n",
    "    y_pred[y_pred == -1] = 1\n",
    "\n",
    "    print(f\"{name} Results:\")\n",
    "    print(evaluation_utils.run_evaluation(y, y_pred, do_point_adjustment=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

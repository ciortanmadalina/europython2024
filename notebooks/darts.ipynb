{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import evaluation_utils, data_utils\n",
    "\n",
    "from darts.models import (\n",
    "    RNNModel,\n",
    "    TCNModel,\n",
    "    TransformerModel,\n",
    "    NBEATSModel,\n",
    "    BlockRNNModel,\n",
    "    VARIMA,\n",
    ")\n",
    "from darts.metrics import mape, smape, mae\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.utils.callbacks import TFMProgressBar\n",
    "\n",
    "from darts import TimeSeries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def generate_torch_kwargs():\n",
    "    # run torch models on CPU, and disable progress bars for all model stages except training.\n",
    "    return {\n",
    "        \"pl_trainer_kwargs\": {\n",
    "            \"accelerator\": \"cpu\",\n",
    "            \"callbacks\": [TFMProgressBar(enable_train_bar_only=True)],\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_utils.get_data('../data/6_cardio.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X)\n",
    "# Create a DatetimeIndex\n",
    "time = pd.date_range(start='2020-01-01', periods=n, freq='D')\n",
    "\n",
    "# df = pd.DataFrame(data=X, index=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X) * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_series_list = [\n",
    "    TimeSeries.from_times_and_values(time[:train_size], col) for col in X_train.T]\n",
    "test_time_series_list = [\n",
    "    TimeSeries.from_times_and_values(time[train_size:], col) for col in X_test.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NBEATSModel(\n",
    "    input_chunk_length=1000,\n",
    "    output_chunk_length=200,\n",
    "    n_epochs=5,\n",
    "    random_state=0,\n",
    "    **generate_torch_kwargs()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | stacks        | ModuleList       | 13.9 M\n",
      "---------------------------------------------------\n",
      "13.9 M    Trainable params\n",
      "7.3 K     Non-trainable params\n",
      "13.9 M    Total params\n",
      "55.608    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964d7930dca74811809c46edfd3d41a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NBEATSModel(output_chunk_shift=0, generic_architecture=True, num_stacks=30, num_blocks=1, num_layers=4, layer_widths=256, expansion_coefficient_dim=5, trend_polynomial_degree=2, dropout=0.0, activation=ReLU, input_chunk_length=1000, output_chunk_length=200, n_epochs=5, random_state=0, pl_trainer_kwargs={'accelerator': 'cpu', 'callbacks': [<darts.utils.callbacks.TFMProgressBar object at 0x0000021B759134F0>]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_time_series_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction\n",
    "# pred = model.historical_forecasts(train_time_series_list,forecast_horizon = 200, retrain=False)\n",
    "# pred = np.array([p.values().reshape(-1) for p in pred]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(n=len(X_test), series=train_time_series_list)\n",
    "pred = np.array([p.values().reshape(-1) for p in pred]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AUCROC': 0.42914438502673796, 'AUCPR': 0.32, 'F1': 0.4848448117817289, 'Precision': 0.32, 'Recall': 1.0, 'Adjusted AUCROC': 0.42914438502673796, 'Adjusted AUCPR': 0.32, 'Adjusted F1': 0.4848448117817289, 'Adjusted Precision': 0.32, 'Adjusted Recall': 1.0}\n"
     ]
    }
   ],
   "source": [
    "y_pred = evaluation_utils.threshold_anomalies(X_test, pred, method=\"filter\")\n",
    "print(evaluation_utils.run_evaluation(\n",
    "    y_test, np.array(y_pred).reshape(-1),\n",
    "    do_point_adjustment=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AUCROC': 0.18816844919786097, 'AUCPR': 0.2891059602649007, 'F1': 0.4848448117817289, 'Precision': 0.32, 'Recall': 1.0, 'Adjusted AUCROC': 0.625668449197861, 'Adjusted AUCPR': 0.38596491228070173, 'Adjusted F1': 0.5569580067586855, 'Adjusted Precision': 0.38596491228070173, 'Adjusted Recall': 1.0}\n"
     ]
    }
   ],
   "source": [
    "y_pred = evaluation_utils.threshold_anomalies(X_test, pred, method=\"aucp\")\n",
    "print(evaluation_utils.run_evaluation(\n",
    "    y_test, np.array(y_pred).reshape(-1),\n",
    "    do_point_adjustment=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
